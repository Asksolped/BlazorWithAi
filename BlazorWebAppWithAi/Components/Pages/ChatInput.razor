@page "/ChatInput"
@rendermode InteractiveServer
@using System.Text
@using System.Text.Json
@using BlazorBootstrap
@using BlazorWebAppWithAi.Models.Ollama
@inject IHttpClientFactory ClientFactory;

<h3>ChatInput</h3>
<AuthorizeView>
    <p>Hello @context.User.Identity?.Name</p>
</AuthorizeView>
<EditForm FormName="ChatPrompt" Model="@_formData" OnSubmit="@HandleValidSubmit">
    <label for="prompt">Type your prompt...</label>
    <InputText id="prompt" @bind-Value="_formData.Prompt" type="text"></InputText>
    <label for="stream"> Enable Stream</label>
    <InputCheckbox id="stream" @bind-Value="_formData.Stream"></InputCheckbox>
    <button type="submit">Submit Prompt</button>
</EditForm>

@*
    Det viser seg at tekstresponsen fra Gemma3, er trent opp på å returnere teksten som markdown format.
Det kan vi bruke for å ferdigformatere teksten vi tar imot. Markdown er et standardisert tekstformat, også brukt av Discord.
Vi kan enten lage en parser for dette selv, eller ta i bruk komponentpakker. De som jobber i front-end er vandt med dette.
Her har jeg tatt i bruk en nuget pakke som heter Blazor.Bootstrap, Les mer og test de forskjellige komponentene tilgjengelig i pakken her:

https://demos.blazorbootstrap.com/

Vi tar i bruk Markdown komponenten her for å ferdigrendre ut ollama responsen vår, fra markdown til html.
Når dere laster ned denne nye oppdateringen kan dere kjøre

dotnet restore

for å hente inn de nye pakkene.
*@
<p>Response: </p><Markdown>@_ollamaResponse</Markdown>
@code {
    private readonly OllamaRequest _formData = new();
    private string _ollamaResponse = string.Empty;

    private async Task HandleValidSubmit()
    {
        _ollamaResponse = string.Empty;
        var client = ClientFactory.CreateClient();
        var content = new StringContent(JsonSerializer.Serialize(_formData), Encoding.UTF8, "application/json");
        Console.WriteLine(await content.ReadAsStringAsync());
        var url = new Uri("http://localhost:11434/api/generate");
        if (_formData.Stream)
        {
            var request = new HttpRequestMessage(HttpMethod.Post, url)
            {
                Content = content
            };
            var response = await client.SendAsync(request, HttpCompletionOption.ResponseHeadersRead);
            await using var stream = await response.Content.ReadAsStreamAsync();
            using var reader = new StreamReader(stream);
            while (!reader.EndOfStream)
            {
                var line = await reader.ReadLineAsync();
                var streamReq = JsonSerializer.Deserialize<OllamaResponse>(line);
                if (streamReq.Done) break;
                _ollamaResponse += streamReq.Response;
                StateHasChanged();
            }
        }
        else
        {
            var response = await client.PostAsync(url, content);
            var chatResponse = await response.Content.ReadFromJsonAsync<OllamaResponse>();
            if (chatResponse is null) return;
            _ollamaResponse = chatResponse.Response;
        }
    }
}